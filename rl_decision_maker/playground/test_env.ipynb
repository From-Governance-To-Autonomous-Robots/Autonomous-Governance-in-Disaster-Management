{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pandas as pd \n",
    "import os \n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(file_path='config.yaml'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TaskSequenceEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(TaskSequenceEnv, self).__init__()\n",
    "        self.CONFIG = load_config(\"/home/julian/git-repo/juliangdz/GovernanceIRP/Autonomous-Governance-in-Disaster-Management/rl_decision_maker/configs/config.yaml\")\n",
    "        self.tasks = self.CONFIG['tasks']\n",
    "        # Load the Datasets for each task\n",
    "        self.info_dataset = self._get_data_based_on_task(\"info\")\n",
    "        self.human_dataset = self._get_data_based_on_task(\"human\")\n",
    "        self.damage_dataset = self._get_data_based_on_task(\"damage\")\n",
    "        self.satellite_dataset = self._get_data_based_on_task(\"satellite\")\n",
    "        self.drone_dataset = self._get_data_based_on_task(\"drone\")\n",
    "        # Store the Seen Indexes of the Records for each Dataset \n",
    "        self.seen_info = []\n",
    "        self.seen_human = []\n",
    "        self.seen_damage = []\n",
    "        self.seen_satellite = []\n",
    "        self.seen_drone = []\n",
    "        \n",
    "        self.credits_info = 5\n",
    "        self.credits_human = 5\n",
    "        self.credits_damage = 5\n",
    "        self.credits_satellite = 5\n",
    "        self.credits_drone = 5\n",
    "        \n",
    "        self.isTreeCorrectlyAnswered = False\n",
    "        self.currentEpisode = 0\n",
    "        self.currentStep = 0\n",
    "        self.tree_counter = 0\n",
    "        self.correct_answered_tree_counter = 0\n",
    "        self.wrongly_answered_tree_counter = 0\n",
    "        \n",
    "        self.task_index = 0\n",
    "        self.current_task_info = None\n",
    "        self.ground_truth = None\n",
    "        self.tree_score = 0\n",
    "\n",
    "        # Define action space\n",
    "        self.action_space = spaces.Discrete(5)  # Actions 0, 1, 2, 3, 4\n",
    "        \n",
    "        # Define observation space\n",
    "        max_length = max([len(self.info_dataset.iloc[0][\"prediction_conf\"]),\n",
    "                          len(self.human_dataset.iloc[0][\"prediction_conf\"]),\n",
    "                          len(self.damage_dataset.iloc[0][\"prediction_conf\"]),\n",
    "                          len(self.satellite_dataset.iloc[0][\"prediction_conf\"]),\n",
    "                          len(self.drone_dataset.iloc[0][\"prediction_conf\"])])\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(max_length + len(self.tasks),), dtype=np.float32)\n",
    "        self.reset()\n",
    "        \n",
    "    def _random_select_record_from_dataset(self, task: str):\n",
    "        \n",
    "        if task == \"info\":\n",
    "            dataset = self.info_dataset\n",
    "        elif task == \"human\":\n",
    "            dataset = self.human_dataset\n",
    "        elif task == \"damage\":\n",
    "            dataset = self.damage_dataset\n",
    "        elif task == \"satellite\":\n",
    "            dataset = self.satellite_dataset\n",
    "        elif task == \"drone\":\n",
    "            dataset = self.drone_dataset\n",
    "        else:\n",
    "            dataset = self.info_dataset\n",
    "        \n",
    "        if dataset.empty:\n",
    "            raise ValueError(\"The dataset is empty\")\n",
    "\n",
    "        if task == \"info\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_info))\n",
    "        elif task == \"human\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_human))\n",
    "        elif task == \"damage\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_damage))\n",
    "        elif task == \"satellite\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_satellite))\n",
    "        elif task == \"drone\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_drone))\n",
    "        else:\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_info))\n",
    "\n",
    "        if not remaining_indices:\n",
    "            raise ValueError(\"All records have been seen\")\n",
    "\n",
    "        selected_idx = random.choice(remaining_indices)\n",
    "        \n",
    "        if task == \"info\":\n",
    "            self.seen_info.append(selected_idx)\n",
    "        elif task == \"human\":\n",
    "            self.seen_human.append(selected_idx)\n",
    "        elif task == \"damage\":\n",
    "            self.seen_damage.append(selected_idx)\n",
    "        elif task == \"satellite\":\n",
    "            self.seen_satellite.append(selected_idx)\n",
    "        elif task == \"drone\":\n",
    "            self.seen_drone.append(selected_idx)\n",
    "        else:\n",
    "            self.seen_info.append(selected_idx)\n",
    "        \n",
    "        return dataset.loc[selected_idx][\"ground_truth\"], dataset.loc[selected_idx][\"prediction_conf\"]\n",
    "\n",
    "    def _handle_gather_additional_data(self,task):\n",
    "        if task == \"info\":\n",
    "            dataset = self.info_dataset\n",
    "        elif task == \"human\":\n",
    "            dataset = self.human_dataset\n",
    "        elif task == \"damage\":\n",
    "            dataset = self.damage_dataset\n",
    "        elif task == \"satellite\":\n",
    "            dataset = self.satellite_dataset\n",
    "        elif task == \"drone\":\n",
    "            dataset = self.drone_dataset\n",
    "        else:\n",
    "            dataset = self.info_dataset\n",
    "        \n",
    "        dataset = dataset[dataset[\"ground_truth\"] == self.ground_truth]\n",
    "        \n",
    "        if dataset.empty:\n",
    "            raise ValueError(\"The dataset is empty\")\n",
    "\n",
    "        if task == \"info\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_info))\n",
    "        elif task == \"human\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_human))\n",
    "        elif task == \"damage\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_damage))\n",
    "        elif task == \"satellite\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_satellite))\n",
    "        elif task == \"drone\":\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_drone))\n",
    "        else:\n",
    "            remaining_indices = list(set(dataset.index) - set(self.seen_info))\n",
    "\n",
    "        if not remaining_indices:\n",
    "            raise ValueError(\"All records have been seen\")\n",
    "\n",
    "        selected_idx = random.choice(remaining_indices)\n",
    "        if task == \"info\":\n",
    "            self.seen_info.append(selected_idx)\n",
    "        elif task == \"human\":\n",
    "            self.seen_human.append(selected_idx)\n",
    "        elif task == \"damage\":\n",
    "            self.seen_damage.append(selected_idx)\n",
    "        elif task == \"satellite\":\n",
    "            self.seen_satellite.append(selected_idx)\n",
    "        elif task == \"drone\":\n",
    "            self.seen_drone.append(selected_idx)\n",
    "        else:\n",
    "            self.seen_info.append(selected_idx)\n",
    "        \n",
    "        return dataset.loc[selected_idx][\"ground_truth\"], dataset.loc[selected_idx][\"prediction_conf\"]\n",
    "    \n",
    "    def _get_data_based_on_task(self, task: str):\n",
    "        dataset = pd.read_csv(os.path.join(self.CONFIG['data_path'], task, f\"{self.CONFIG['phase']}_inference_results.csv\"))\n",
    "        dataset[\"prediction_conf\"] = dataset[\"prediction_conf\"].apply(lambda x:list(map(float, x.strip(\"[]\").split())))\n",
    "        return dataset\n",
    "    \n",
    "    def reset(self):\n",
    "        self.seen_info = []\n",
    "        self.seen_human = []\n",
    "        self.seen_damage = []\n",
    "        self.seen_satellite = []\n",
    "        self.seen_drone = []\n",
    "        \n",
    "        self.credits_info = 5\n",
    "        self.credits_human = 5\n",
    "        self.credits_damage = 5\n",
    "        self.credits_satellite = 5\n",
    "        self.credits_drone = 5\n",
    "        \n",
    "        self.isTreeCorrectlyAnswered = False\n",
    "        self.number_of_times_additional_data_requested = 0\n",
    "        self.currentStep = 0\n",
    "        \n",
    "        self.task_index = 0\n",
    "        self.tree_score = 0\n",
    "        self.ground_truth, self.current_task_info = self.get_task_data()\n",
    "        print('In reset: ',self.task_index)\n",
    "        return self._get_observation()\n",
    "    \n",
    "\n",
    "    def get_task_data(self):\n",
    "        task = self.tasks[self.task_index]\n",
    "        return self._random_select_record_from_dataset(task)\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        task_vector = np.zeros(len(self.tasks))\n",
    "        task_vector[self.task_index] = 1\n",
    "        task_info = self.current_task_info\n",
    "        observation = np.concatenate([task_vector, task_info])\n",
    "        return observation\n",
    "\n",
    "    def step(self, action):\n",
    "        print('-----------[STEP]--------')\n",
    "        print(f'[INFO] In Tree  with current task : {self.tasks[self.task_index]}')\n",
    "        reward = 0\n",
    "        done = False\n",
    "        \n",
    "        if action == 4:\n",
    "            task = self.tasks[self.task_index]\n",
    "            if task == \"info\":\n",
    "                if self.credits_info != 0:\n",
    "                    self.credits_info -= 1\n",
    "                    self.ground_truth, self.current_task_info = self._handle_gather_additional_data(task)\n",
    "                    reward = -1\n",
    "                    self.number_of_times_additional_data_requested += 1\n",
    "                    \n",
    "            elif task == \"human\":\n",
    "                if self.credits_human != 0:\n",
    "                    self.credits_human -= 1\n",
    "                    self.ground_truth, self.current_task_info = self._handle_gather_additional_data(task)\n",
    "                    self.number_of_times_additional_data_requested += 1\n",
    "                    reward = -1\n",
    "            \n",
    "            elif task == \"damage\":\n",
    "                if self.credits_damage != 0:\n",
    "                    self.credits_damage -= 1\n",
    "                    self.ground_truth, self.current_task_info = self._handle_gather_additional_data(task)\n",
    "                    self.number_of_times_additional_data_requested += 1\n",
    "                    reward = -1\n",
    "            \n",
    "            elif task == \"satellite\":\n",
    "                if self.credits_satellite != 0:\n",
    "                    self.credits_satellite -= 1\n",
    "                    self.ground_truth, self.current_task_info = self._handle_gather_additional_data(task)\n",
    "                    self.number_of_times_additional_data_requested += 1\n",
    "                    reward = -1\n",
    "            \n",
    "            elif task == \"drone\":\n",
    "                if self.credits_drone != 0:\n",
    "                    self.credits_drone -= 1\n",
    "                    self.ground_truth, self.current_task_info = self._handle_gather_additional_data(task)\n",
    "                    self.number_of_times_additional_data_requested += 1\n",
    "                    reward = -1\n",
    "            \n",
    "            print(f'[INFO] : In Gather Additional Data for {task}')\n",
    "            \n",
    "        elif action == self.ground_truth:\n",
    "            reward = 1\n",
    "            self.task_index += 1\n",
    "            self.correct_answered_tree_counter +=1\n",
    "            self.isTreeCorrectlyAnswered = True\n",
    "        \n",
    "        elif action != self.ground_truth:\n",
    "            reward = -5\n",
    "            self.task_index += 1\n",
    "            self.wrongly_answered_tree_counter +=1\n",
    "            self.isTreeCorrectlyAnswered = False\n",
    "        \n",
    "        if self.task_index >= len(self.tasks):\n",
    "            self.tree_counter += 1\n",
    "            done = True\n",
    "            self.task_index = 0\n",
    "            task = self.tasks[self.task_index]\n",
    "            self.ground_truth, self.current_task_info = self._random_select_record_from_dataset(task)\n",
    "            print(f'[INFO] Tasks Len : ',len(self.tasks))\n",
    "            print(f'[INFO] Tree Completed - Next task : {self.tasks[self.task_index]}')\n",
    "        else:\n",
    "            task = self.tasks[self.task_index]\n",
    "            print('Next Task Index : ',self.task_index)\n",
    "            self.ground_truth, self.current_task_info = self._random_select_record_from_dataset(task)\n",
    "\n",
    "        self.tree_score += reward\n",
    "        \n",
    "        if done:\n",
    "            self.currentEpisode += 1\n",
    "        \n",
    "        info = {\n",
    "            \"tree_score\": self.tree_score,\n",
    "            \"isTreeCorrectlyAnswered\":self.isTreeCorrectlyAnswered,\n",
    "            \"currentEpisode\":self.currentEpisode,\n",
    "            \"currentStep\":self.currentStep,\n",
    "            \"tree_id\":self.tree_counter,\n",
    "            \"currentStepReward\":reward,\n",
    "            \"number_of_correctly_answered_trees\":self.correct_answered_tree_counter,\n",
    "            \"number_of_wrongly_answered_trees\":self.wrongly_answered_tree_counter,\n",
    "            \"number_of_times_additional_data_requested\":self.number_of_times_additional_data_requested\n",
    "        }\n",
    "        \n",
    "        return self._get_observation(), reward, done, info \n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In reset:  0\n",
      "Starting episode 1\n",
      "In reset:  0\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : info\n",
      "Next Task Index :  1\n",
      "Action: 1\n",
      "Observation: [0.         1.         0.         0.         0.         0.05708037\n",
      " 0.12787731 0.01692019 0.7981221 ]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -5, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 0, 'currentStep': 0, 'tree_id': 0, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 0, 'number_of_wrongly_answered_trees': 1, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : human\n",
      "Next Task Index :  2\n",
      "Action: 2\n",
      "Observation: [0.        0.        1.        0.        0.        0.8361429 0.1638571]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -10, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 0, 'currentStep': 0, 'tree_id': 0, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 0, 'number_of_wrongly_answered_trees': 2, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : damage\n",
      "Next Task Index :  3\n",
      "Action: 2\n",
      "Observation: [0.         0.         0.         1.         0.         0.73105854\n",
      " 0.731057  ]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -15, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 0, 'currentStep': 0, 'tree_id': 0, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 0, 'number_of_wrongly_answered_trees': 3, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : satellite\n",
      "Next Task Index :  4\n",
      "Action: 1\n",
      "Observation: [0.         0.         0.         0.         1.         0.50132114\n",
      " 0.50126135]\n",
      "Reward: 1\n",
      "Done: False\n",
      "Info: {'tree_score': -14, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 0, 'currentStep': 0, 'tree_id': 0, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 1, 'number_of_wrongly_answered_trees': 3, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : drone\n",
      "[INFO] Tasks Len :  5\n",
      "[INFO] Tree Completed - Next task : info\n",
      "Action: 2\n",
      "Observation: [1.         0.         0.         0.         0.         0.9482518\n",
      " 0.05174822]\n",
      "Reward: -5\n",
      "Done: True\n",
      "Info: {'tree_score': -19, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 1, 'currentStep': 0, 'tree_id': 1, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 1, 'number_of_wrongly_answered_trees': 4, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "Episode 1 ended with total reward: -19\n",
      "Trees Completed: 1\n",
      "Correct Trees: 1\n",
      "Failed Trees: 4\n",
      "Tree Score: -19\n",
      "==================================================\n",
      "Starting episode 2\n",
      "In reset:  0\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : info\n",
      "Next Task Index :  1\n",
      "Action: 1\n",
      "Observation: [0.         1.         0.         0.         0.         0.00219858\n",
      " 0.98896736 0.00266723 0.00616677]\n",
      "Reward: 1\n",
      "Done: False\n",
      "Info: {'tree_score': 1, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 1, 'currentStep': 0, 'tree_id': 1, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 2, 'number_of_wrongly_answered_trees': 4, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : human\n",
      "Next Task Index :  2\n",
      "Action: 3\n",
      "Observation: [0.         0.         1.         0.         0.         0.00698003\n",
      " 0.99302   ]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -4, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 1, 'currentStep': 0, 'tree_id': 1, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 2, 'number_of_wrongly_answered_trees': 5, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : damage\n",
      "Next Task Index :  3\n",
      "Action: 1\n",
      "Observation: [0.         0.         0.         1.         0.         0.73105854\n",
      " 0.73105067]\n",
      "Reward: 1\n",
      "Done: False\n",
      "Info: {'tree_score': -3, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 1, 'currentStep': 0, 'tree_id': 1, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 5, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : satellite\n",
      "Next Task Index :  4\n",
      "Action: 3\n",
      "Observation: [0.        0.        0.        0.        1.        0.5000177 0.5000391]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -8, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 1, 'currentStep': 0, 'tree_id': 1, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 6, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : drone\n",
      "[INFO] Tasks Len :  5\n",
      "[INFO] Tree Completed - Next task : info\n",
      "Action: 1\n",
      "Observation: [1.         0.         0.         0.         0.         0.39938542\n",
      " 0.6006146 ]\n",
      "Reward: -5\n",
      "Done: True\n",
      "Info: {'tree_score': -13, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 2, 'currentStep': 0, 'tree_id': 2, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 7, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "Episode 2 ended with total reward: -13\n",
      "Trees Completed: 2\n",
      "Correct Trees: 3\n",
      "Failed Trees: 7\n",
      "Tree Score: -13\n",
      "==================================================\n",
      "Starting episode 3\n",
      "In reset:  0\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : info\n",
      "Next Task Index :  1\n",
      "Action: 2\n",
      "Observation: [0.         1.         0.         0.         0.         0.01463764\n",
      " 0.9718099  0.00162651 0.01192593]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -5, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 2, 'currentStep': 0, 'tree_id': 2, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 8, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : human\n",
      "Next Task Index :  2\n",
      "Action: 0\n",
      "Observation: [0.         0.         1.         0.         0.         0.8256723\n",
      " 0.17432766]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -10, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 2, 'currentStep': 0, 'tree_id': 2, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 9, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : damage\n",
      "Next Task Index :  3\n",
      "Action: 3\n",
      "Observation: [0.         0.         0.         1.         0.         0.73105687\n",
      " 0.5000002 ]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -15, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 2, 'currentStep': 0, 'tree_id': 2, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 10, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : satellite\n",
      "Next Task Index :  4\n",
      "Action: 2\n",
      "Observation: [0.        0.        0.        0.        1.        0.5509077 0.5383432]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -20, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 2, 'currentStep': 0, 'tree_id': 2, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 11, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : drone\n",
      "[INFO] Tasks Len :  5\n",
      "[INFO] Tree Completed - Next task : info\n",
      "Action: 3\n",
      "Observation: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.9950564e-01 4.9431878e-04]\n",
      "Reward: -5\n",
      "Done: True\n",
      "Info: {'tree_score': -25, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 3, 'currentStep': 0, 'tree_id': 3, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 3, 'number_of_wrongly_answered_trees': 12, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "Episode 3 ended with total reward: -25\n",
      "Trees Completed: 3\n",
      "Correct Trees: 3\n",
      "Failed Trees: 12\n",
      "Tree Score: -25\n",
      "==================================================\n",
      "Starting episode 4\n",
      "In reset:  0\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : info\n",
      "Next Task Index :  1\n",
      "Action: 0\n",
      "Observation: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.7386866e-04 5.7125039e-04 9.9557614e-01 3.6786995e-03]\n",
      "Reward: 1\n",
      "Done: False\n",
      "Info: {'tree_score': 1, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 3, 'currentStep': 0, 'tree_id': 3, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 4, 'number_of_wrongly_answered_trees': 12, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : human\n",
      "Next Task Index :  2\n",
      "Action: 0\n",
      "Observation: [0.         0.         1.         0.         0.         0.7142397\n",
      " 0.28576028]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -4, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 3, 'currentStep': 0, 'tree_id': 3, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 4, 'number_of_wrongly_answered_trees': 13, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : damage\n",
      "Next Task Index :  3\n",
      "Action: 1\n",
      "Observation: [0.         0.         0.         1.         0.         0.73105544\n",
      " 0.7057252 ]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -9, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 3, 'currentStep': 0, 'tree_id': 3, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 4, 'number_of_wrongly_answered_trees': 14, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : satellite\n",
      "Next Task Index :  4\n",
      "Action: 0\n",
      "Observation: [0.         0.         0.         0.         1.         0.72942567\n",
      " 0.5019978 ]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -14, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 3, 'currentStep': 0, 'tree_id': 3, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 4, 'number_of_wrongly_answered_trees': 15, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : drone\n",
      "[INFO] Tasks Len :  5\n",
      "[INFO] Tree Completed - Next task : info\n",
      "Action: 1\n",
      "Observation: [1.         0.         0.         0.         0.         0.7444241\n",
      " 0.25557587]\n",
      "Reward: 1\n",
      "Done: True\n",
      "Info: {'tree_score': -13, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 4, 'currentStep': 0, 'tree_id': 4, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 5, 'number_of_wrongly_answered_trees': 15, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "Episode 4 ended with total reward: -13\n",
      "Trees Completed: 4\n",
      "Correct Trees: 5\n",
      "Failed Trees: 15\n",
      "Tree Score: -13\n",
      "==================================================\n",
      "Starting episode 5\n",
      "In reset:  0\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : info\n",
      "Next Task Index :  1\n",
      "Action: 1\n",
      "Observation: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 6.4791681e-04 2.2108643e-03 9.8836333e-01 8.7779686e-03]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -5, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 4, 'currentStep': 0, 'tree_id': 4, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 5, 'number_of_wrongly_answered_trees': 16, 'number_of_times_additional_data_requested': 0}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : human\n",
      "[INFO] : In Gather Additional Data for human\n",
      "Next Task Index :  1\n",
      "Action: 4\n",
      "Observation: [0.         1.         0.         0.         0.         0.09307905\n",
      " 0.0031548  0.00384724 0.89991885]\n",
      "Reward: -1\n",
      "Done: False\n",
      "Info: {'tree_score': -6, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 4, 'currentStep': 0, 'tree_id': 4, 'currentStepReward': -1, 'number_of_correctly_answered_trees': 5, 'number_of_wrongly_answered_trees': 16, 'number_of_times_additional_data_requested': 1}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : human\n",
      "Next Task Index :  2\n",
      "Action: 3\n",
      "Observation: [0.         0.         1.         0.         0.         0.94497806\n",
      " 0.05502192]\n",
      "Reward: 1\n",
      "Done: False\n",
      "Info: {'tree_score': -5, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 4, 'currentStep': 0, 'tree_id': 4, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 6, 'number_of_wrongly_answered_trees': 16, 'number_of_times_additional_data_requested': 1}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : damage\n",
      "Next Task Index :  3\n",
      "Action: 2\n",
      "Observation: [0.        0.        0.        1.        0.        0.7310585 0.5      ]\n",
      "Reward: -5\n",
      "Done: False\n",
      "Info: {'tree_score': -10, 'isTreeCorrectlyAnswered': False, 'currentEpisode': 4, 'currentStep': 0, 'tree_id': 4, 'currentStepReward': -5, 'number_of_correctly_answered_trees': 6, 'number_of_wrongly_answered_trees': 17, 'number_of_times_additional_data_requested': 1}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : satellite\n",
      "Next Task Index :  4\n",
      "Action: 0\n",
      "Observation: [0.         0.         0.         0.         1.         0.5002824\n",
      " 0.50015783]\n",
      "Reward: 1\n",
      "Done: False\n",
      "Info: {'tree_score': -9, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 4, 'currentStep': 0, 'tree_id': 4, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 7, 'number_of_wrongly_answered_trees': 17, 'number_of_times_additional_data_requested': 1}\n",
      "-------------------------\n",
      "-----------[STEP]--------\n",
      "[INFO] In Tree  with current task : drone\n",
      "[INFO] Tasks Len :  5\n",
      "[INFO] Tree Completed - Next task : info\n",
      "Action: 0\n",
      "Observation: [1.         0.         0.         0.         0.         0.9152028\n",
      " 0.08479718]\n",
      "Reward: 1\n",
      "Done: True\n",
      "Info: {'tree_score': -8, 'isTreeCorrectlyAnswered': True, 'currentEpisode': 5, 'currentStep': 0, 'tree_id': 5, 'currentStepReward': 1, 'number_of_correctly_answered_trees': 8, 'number_of_wrongly_answered_trees': 17, 'number_of_times_additional_data_requested': 1}\n",
      "-------------------------\n",
      "Episode 5 ended with total reward: -8\n",
      "Trees Completed: 5\n",
      "Correct Trees: 8\n",
      "Failed Trees: 17\n",
      "Tree Score: -8\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Assuming TaskSequenceEnv and CONFIG are already defined\n",
    "# Initialize the environment\n",
    "env = TaskSequenceEnv()\n",
    "\n",
    "# Number of episodes to test\n",
    "num_episodes = 5\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print(f\"Starting episode {episode + 1}\")\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Randomly select an action\n",
    "        action = env.action_space.sample()\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Print the details of the step\n",
    "        print(f\"Action: {action}\")\n",
    "        print(f\"Observation: {next_obs}\")\n",
    "        print(f\"Reward: {reward}\")\n",
    "        print(f\"Done: {done}\")\n",
    "        print(f\"Info: {info}\")\n",
    "        print('-------------------------')\n",
    "\n",
    "    print(f\"Episode {episode + 1} ended with total reward: {total_reward}\")\n",
    "    print(f\"Trees Completed: {env.tree_counter}\")\n",
    "    print(f\"Correct Trees: {env.correct_answered_tree_counter}\")\n",
    "    print(f\"Failed Trees: {env.wrongly_answered_tree_counter}\")\n",
    "    print(f\"Tree Score: {env.tree_score}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
